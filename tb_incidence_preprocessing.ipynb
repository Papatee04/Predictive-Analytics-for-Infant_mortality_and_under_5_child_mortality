{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpmdarima\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsaplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_acf, plot_pacf\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\__init__.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Stuff we want at top-level\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima, ARIMA, AutoARIMA, StepwiseContext, decompose\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf, autocorr_plot, c, pacf, plot_acf, plot_pacf, \\\n\u001b[0;32m     54\u001b[0m     tsdisplay\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\arima\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapprox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\arima\\approx.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# R approx function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m c, check_endog\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_callable\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\utils\\array.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m C_intgrt_vec\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_series\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_iterable\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_series\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mc:\\Users\\tlche\\OneDrive\\Documents\\GitHub\\Predictive-Analytics-for-Tuberculosis-TB-Incidence-and-Treatment-Adherence\\tbvenv\\Lib\\site-packages\\pmdarima\\utils\\_array.pyx:1\u001b[0m, in \u001b[0;36minit pmdarima.utils._array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Using pandas to load the CSV file into a DataFrame.\n",
    "# Inspecting the first few rows to understand the structure and content.\n",
    "df = pd.read_csv('stop_tb_data2.csv')\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of missing values per column\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Checking the percentage of missing values per column\n",
    "missing_values_percentage = df.isnull().mean() * 100\n",
    "\n",
    "# Print results\n",
    "print(missing_values_count)\n",
    "print(missing_values_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with more than 60% missing values\n",
    "\n",
    "\n",
    "df = df.dropna(thresh=len(df) * 0.6, axis=1)\n",
    "\n",
    "# Filling missing values with median for numerical columns\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of missing values per column again\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Checking the percentage of missing values per column again\n",
    "missing_values_percentage = df.isnull().mean() * 100\n",
    "\n",
    "# Print results\n",
    "print(missing_values_count)\n",
    "print(missing_values_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Display a summary of the dataframe to check data types and non-null counts\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric or irrelevant columns\n",
    "df_filtered = df.drop(columns=['country_name', 'iso3_code', 'g_whoregion'])\n",
    "\n",
    "# Convert remaining categorical columns to numeric using one-hot encoding\n",
    "df_numeric = pd.get_dummies(df_filtered, drop_first=True)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Create a heatmap to visualize the correlation matrix\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WHO dataset\n",
    "who_df = pd.read_csv('tb_incidence_data_zambia.csv')\n",
    "\n",
    "# Rename 'Year' to 'year' in who_df \n",
    "who_df.rename(columns={'Year': 'year'}, inplace=True)\n",
    "\n",
    "# Now merge again\n",
    "merged_df = pd.merge(df, who_df, on='year', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "merged_df.to_csv('merged_tb_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that start with 'e_' or 'estimated'\n",
    "columns_to_drop = [col for col in merged_df.columns if col.startswith('e_') or col.startswith('estimated')]\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "merged_df_encoded = pd.get_dummies(merged_df, drop_first=True)\n",
    "\n",
    "# List of target variables\n",
    "target_vars = ['TB cases per 100 000', 'Number of incident tuberculosis cases']\n",
    "\n",
    "# Compute the correlation matrix for all variables against the target variables\n",
    "correlation_matrix = merged_df_encoded.corr()\n",
    "\n",
    "# Extract correlations with the target variables\n",
    "correlation_with_tb = correlation_matrix[target_vars].dropna()\n",
    "\n",
    "# Display the correlation matrix for inspection\n",
    "print(correlation_with_tb)\n",
    "\n",
    "# Generate a heatmap for the correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(22, 18))\n",
    "sns.heatmap(correlation_with_tb, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix with TB cases per 100,000 and Incident TB Cases')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Ensure 'year' is the index\n",
    "merged_df_encoded['year'] = pd.to_datetime(merged_df_encoded['year'], format='%Y')\n",
    "merged_df_encoded.set_index('year', inplace=True)\n",
    "\n",
    "# Select the two target variables\n",
    "tb_cases = merged_df_encoded['TB cases per 100 000']\n",
    "tb_incidence = merged_df_encoded['Number of incident tuberculosis cases']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(tb_cases) * 0.8)\n",
    "train_tb_cases, test_tb_cases = tb_cases[:train_size], tb_cases[train_size:]\n",
    "train_tb_incidence, test_tb_incidence = tb_incidence[:train_size], tb_incidence[train_size:]\n",
    "\n",
    "# Function to build and evaluate ARIMA model\n",
    "def arima_forecast(train, test, order=(1,1,1)):\n",
    "    # Fit ARIMA model\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model_fit.forecast(steps=len(test))\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "    print(f'RMSE: {rmse}')\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train.index, train, label='Train Data')\n",
    "    plt.plot(test.index, test, label='Test Data', color='orange')\n",
    "    plt.plot(test.index, predictions, label='Predictions', color='green')\n",
    "    plt.title('ARIMA Forecast')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model_fit, predictions\n",
    "\n",
    "# Build ARIMA model for 'TB cases per 100 000'\n",
    "print(\"Model for 'TB cases per 100 000'\")\n",
    "arima_tb_cases, tb_cases_predictions = arima_forecast(train_tb_cases, test_tb_cases)\n",
    "\n",
    "# Build ARIMA model for 'Number of incident tuberculosis cases'\n",
    "print(\"\\nModel for 'Number of incident tuberculosis cases'\")\n",
    "arima_tb_incidence, tb_incidence_predictions = arima_forecast(train_tb_incidence, test_tb_incidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "merged_df_encoded['year'] = pd.to_datetime(merged_df_encoded['year'], format='%Y')\n",
    "merged_df_encoded.set_index('year', inplace=True)\n",
    "\n",
    "# Select the target and exogenous variables\n",
    "tb_cases = merged_df_encoded['TB cases per 100 000']\n",
    "tb_incidence = merged_df_encoded['Number of incident tuberculosis cases']\n",
    "hiv_rates = merged_df_encoded['HIV rates']  # Example exogenous variable\n",
    "population = merged_df_encoded['Population']  # Another exogenous variable\n",
    "\n",
    "# Combine exogenous variables into a matrix (X)\n",
    "exog = merged_df_encoded[['HIV rates', 'Population']]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(tb_cases) * 0.8)\n",
    "train_tb_cases, test_tb_cases = tb_cases[:train_size], tb_cases[train_size:]\n",
    "train_tb_incidence, test_tb_incidence = tb_incidence[:train_size], tb_incidence[train_size:]\n",
    "\n",
    "# Also split exogenous variables for training and testing\n",
    "train_exog, test_exog = exog[:train_size], exog[train_size:]\n",
    "\n",
    "# 1. Function to build and evaluate ARIMA model with auto ARIMA\n",
    "def arima_forecast_with_auto(train, test, exog_train=None, exog_test=None):\n",
    "    # Use auto_arima to find the best order\n",
    "    model = pm.auto_arima(train, exogenous=exog_train, seasonal=False, trace=True,\n",
    "                          suppress_warnings=True, stepwise=True)\n",
    "    print(f'Best ARIMA order: {model.order}')\n",
    "    \n",
    "    # Fit ARIMA model\n",
    "    model_fit = model.fit(train, exogenous=exog_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model_fit.predict(n_periods=len(test), exogenous=exog_test)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "    print(f'RMSE: {rmse}')\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train.index, train, label='Train Data')\n",
    "    plt.plot(test.index, test, label='Test Data', color='orange')\n",
    "    plt.plot(test.index, predictions, label='Predictions', color='green')\n",
    "    plt.title('ARIMA Forecast with Exogenous Variables')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model_fit, predictions\n",
    "\n",
    "# 2. Function for model diagnostics\n",
    "def model_diagnostics(model_fit):\n",
    "    residuals = model_fit.resid()\n",
    "    \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(residuals)\n",
    "    plt.title('Residuals of the ARIMA Model')\n",
    "    \n",
    "    # Plot ACF and PACF of the residuals\n",
    "    plt.subplot(212)\n",
    "    plot_acf(residuals, ax=plt.gca(), lags=20)\n",
    "    plt.show()\n",
    "    \n",
    "    # Perform statistical test to ensure residuals are white noise\n",
    "    ljung_box_test = sm.stats.acorr_ljungbox(residuals, lags=[20], return_df=True)\n",
    "    print(\"Ljung-Box Test p-value:\", ljung_box_test[\"lb_pvalue\"].values)\n",
    "    \n",
    "    if ljung_box_test[\"lb_pvalue\"].values[0] > 0.05:\n",
    "        print(\"Residuals resemble white noise.\")\n",
    "    else:\n",
    "        print(\"Residuals do not resemble white noise.\")\n",
    "\n",
    "# 3. Build ARIMA model for 'TB cases per 100 000' with exogenous variables\n",
    "print(\"Model for 'TB cases per 100 000' with exogenous variables\")\n",
    "arima_tb_cases_exog, tb_cases_predictions_exog = arima_forecast_with_auto(train_tb_cases, test_tb_cases, exog_train=train_exog, exog_test=test_exog)\n",
    "\n",
    "# Model diagnostics\n",
    "model_diagnostics(arima_tb_cases_exog)\n",
    "\n",
    "# 4. Build ARIMA model for 'Number of incident tuberculosis cases' with exogenous variables\n",
    "print(\"\\nModel for 'Number of incident tuberculosis cases' with exogenous variables\")\n",
    "arima_tb_incidence_exog, tb_incidence_predictions_exog = arima_forecast_with_auto(train_tb_incidence, test_tb_incidence, exog_train=train_exog, exog_test=test_exog)\n",
    "\n",
    "# Model diagnostics\n",
    "model_diagnostics(arima_tb_incidence_exog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
